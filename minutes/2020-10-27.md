# GraphBLAS Spec Working Group Meeting Minutes - October 27, 2020

## Attendees
- [X] Ben Brock
- [X] Aydin Buluc
- [X] Tim Mattson
- [X] Scott McMillan
- [X] Jose Moreira



## Minutes


### Multithreaded GraphBLAS:

We are making progress on this extremely complicated problem.  How does the GraphBLAS API interact with a multithreaded system?  There are two sets of issues: one simple and the other messy.

####The simple issue: Section 2.8.2 uses the term "thread safety" incorrectly

A library is said to be "Thread safe" when two of more threads can call functions from the library concurrently without any variables shared between them and the resulting values are same results as if they were called sequentially.

For example, you can call the printf function from the stdio.h library from multiple threads and the output will correctly appear on stdout.   The output records will be interleaved but individual records will appear correctly without conflicts.

We need to rename the section to read "Multithreaded Execution" or maybe "Race Free multithreaded execution".

#### The more complicated issue.

We went through a sequence of examples to explain the two central issues of multithreaded execution.  Threads execute concurrently.  That means statements from the threads are unordered with respect to each other.   A synchronized-with relation between threads creates distinct ordering constraints between statements execution by different threads.

The language definition defines "sequence points" in a serial execution.  Those sequence points define a happens-before relationship in a serial execution.  A synchronized-with relation creates an ordering between threads.  Points sequenced before a synchronized-with relation on one thread happen-before statements sequenced after the synchronized-with relation on another thread.   

A correctly synchronized program defines happens-before relations such that loads and stores are ordered unambiguously such that there are no data races.  A program with a data race is incorrect.  But it is not enough to define the happens before relations.  You also need to deal with the memory orders.  A compiler reorders operations and it cannot know how that order interacts with execution with another thread. Hence the updates across a memory hierarchy while well defined for serial execution may be incorrect in a multithreaded execution.   

Since we are defining a library API, we do not have the ability to redefine the memory consistency model for the host language.  We have to work with what we are given.   Here is how I think we can proceed.  We need the following definitions.

On return from a call to GrB_wait(obj), the state of obj ?complete?.  This means that any graphBLAS method that follows GrB_wait(obj) can safely use obj as an in or inout argument even if the method calls are in different threads.


A GraphBLAS sequence is the DAG of calls to GraphBLAS methods that defines an object at any point in a program.

An object is defined by a sequence of GraphBLAS methods.  An object is materialized when it is: (1) complete, (2) The computations defined by the sequence have completed and will not consume any additional computational resources, and (3) any errors associated with that sequence are available to be read according to the GraphBLAS error model.

This implies that an OpenMP program implementing a producer/consumer pair with calls to GraphBLAS would need to do the following:

// GrB_matrices A, B, C,D; 
int flag = 0;
#pragma omp parallel num_threads(2) shared(A,B,C,D,flag)
{  //lets assume I got two threads

Int ID = omp_get_thread_num();
If (id ==0){
   A = GrB_mxm(B,C);   
   GrB_wait(A)
   int tmp = flag;
   tmp++;
   #pragma omp atomic write seq_cst
   flag = tmp;
   B = GrB_mxm(E,F)
else if (id ==1)
{
Int tmp = 0;
while(tmp ==0) {
#pragma omp atomic read seq_cst
    tmp = flag;
}
D=GrB_mxm(A,C);

}

We agreed in principle that this works for us.  Basically, a sufficiently sophisticated runtime implementing the GraphBLAS API could use GraphBLAS_wait() as a no-op since the condition of being complete would be satisfied by each GraphBLAS method call.   The nonblocking mode with lazy evaluation of a sequence for each object would have total flexibility across threads.  For implementations that need to resolve pending operations before safe reads are allowed across threads could use the GrB_wait() as an entry point into the runtime to force completion. 

Basically, by separating the concept of materialization from completion, we give implementors the freedom they need for aggressive optimization without blocking implementations that need to support move constrained environments (e.g. the windows C environment).  

The next step is for Tim to go through the specification and identify places where we imply completion and materialization.   

### C++ API:

NSTR?    WTHDNSTRM?

### C API: apply(i) and select operations

Is there a way to detect an error of using an `GrB_IndexUnaryOp` that requires an array of two indices with a Vector operation that only provides an array of one index.

I propose a `getRank` method on `GrB_IndexUnaryOp`'s so that this can be an API error check.
